---
title: "Biogeography of European whitefish"
author: "Marco Crotti"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Pipeline for UK whitefish biogeography project using ddRADseq

### Set up working environment
Let's create the folders that are going to contain the output data from all the pipeline components.

```{bash, eval = FALSE}
mkdir ./Desktop/biogeography
mkdir ./Desktop/biogeography/00.Raw_reads ./Desktop/biogeography/01.Demultiplexed_reads ./Desktop/biogeography/02.Trimmomatic_filtering ./Desktop/biogeography/03.Assembly ./Desktop/biogeography/04.bam_alignments ./Desktop/biogeography/05.Stacks ./Desktop/biogeography/06.Phylogenetics ./Desktop/biogeography/07.Population_genetics
```

### Preparing the data for population genomics analyses
We are going to demultiplex raw reads, filter low reads out, align to reference genome, and build a STACKS catalog.

#### 01. Demultiplex raw reads
Use [process_radtags](http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php) to demultiplex Illumina raw data.

```{bash, eval = FALSE}
process_radtags -P -c -q -r -p ./00.Raw_reads/ -o ./01.Demultiplexed_reads -b ./biogeography_barcodes.txt --inline_inline -i gzfastq -y gzfastq --renz_1 pstI --renz_2 mspI -t 65

```

#### 02. [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) filtering

Remove the first 5 bp and 3 bp from the forward and reverse reads to remove the enzyme cut site, single end reads.

```{bash, eval = FALSE}
# Forward reads
for infile in ./01.Demultiplexed_reads/*.1.fq.gz
do
base=$(basename $infile .fq.gz)
java -jar /usr/local/bin/trimmomatic-0.38.jar SE -threads 4 $infile ./02.Trimmomatic_filtering/$base.fq.gz HEADCROP:5
done

# Reverse reads
for infile in ./01.Demultiplexed_reads/*.2.fq.gz
do
base=$(basename $infile .fq.gz)
java -jar /usr/local/bin/trimmomatic-0.38.jar SE -threads 4 $infile ./02.Trimmomatic_filtering/$base.fq.gz HEADCROP:3
done
```


Do paired-end filtering.

```{bash, eval = FALSE}
for R1 in *.1.fq.gz
do
R2=${R1//1.fq.gz/2.fq.gz}
R1paired=${R1//.1.fq.gz/.P1.fq.gz}
R1unpaired=${R1//.1.fq.gz/.U1.fq.gz}	
R2paired=${R2//.2.fq.gz/.P2.fq.gz}
R2unpaired=${R2//.2.fq.gz/.U2.fq.gz}
echo "$R1 $R2"
java -jar /usr/local/bin/trimmomatic-0.38.jar PE -threads 4 -phred33 $R1 $R2 ./02.Trimmomatic_filtering/$R1paired $R1unpaired ./02.Trimmomatic_filtering/$R2paired $R2unpaired LEADING:20 TRAILING:20 MINLEN:60
done
```

#### 03. Align to European whitefish genome assembly
We are using [bwa](http://bio-bwa.sourceforge.net/) aligner for short reads.

```{bash, eval = FALSE}
for R1 in ./02.Trimmomatic_filtering/*.P1.fq.gz
do
R2=${R1//.P1.fq.gz/.P2.fq.gz}
base=$(basename $R1 .P1.fq.gz)
echo "$base"
bwa mem -t 4 /03.Assembly/EW_assembly.fa $R1 $R2 | samtools view -bSq 20 | \
samtools sort -o ./04.bam_alignments/$base.bam
done
```


#### 04. Build Stacks catalog

For this project we used [STACKS v.2.4.1](http://catchenlab.life.illinois.edu/stacks/). We are using the `ref_map.pl` script to build a catalog with referenced aligned reads.

```{bash, eval = FALSE}
ref_map.pl -T 4 --samples ./04.bam_alignments/ -o ./05.Stacks --popmap ./popmap_biogeography.txt
```


### Population genomics and phylogenetics analyses 

From this point onward, we are filtering and generating datasets for different analyses.

#### Generate a vcf file using [populations](http://catchenlab.life.illinois.edu/stacks/comp/populations.php)

Here we are telling `populations` to retain loci only if present in at least 80% of individuals per population in at least 9 populations. We are also removing loci with heterozygosity higher than 0.6 and minor allele frequency below 0.05. Only one snp per locus is retained to reduce the effect of linkage.

```{bash, eval = FALSE}
populations -P ./05.Stacks -M ./popmap_biogeography2.txt -t 4 -p 9 -r 0.8 --max_obs_het 0.6 --min_maf 0.05 --write_single_snp --vcf
```

##### Filter the vcf file

Here we are using vcftools to further filter the vcf file: minimum SNP depth of 5, minimum mean SNP depth of 10, maximum mean depth of 30, maf of 0.05, 85% of individuals need to have the site.

```{bash, eval = FALSE}
vcftools --vcf ./05.Stacks/populations.snps.vcf --minDP 5 --maxDP 30 --min-meanDP 10 --max-meanDP 30 --maf 0.05 --max-missing 0.85 --recode --recode-INFO-all --out ./5.Stacks/filtered.maf5
```

We then use the `filter_hwe_by_pop.pl` script from the [dDocent](http://www.ddocent.com/) pipeline. This script removes sites that are not in HWE within populations.

```{bash, eval = FALSE}
./filter_hwe_by_pop.pl -v ./05.Stacks_/filtered.maf5.recode.vcf -p ./popmap_biogeography2.txt -o ./05.Stacks/filtered.hwe.maf5
```

We found no loci out of HWE. Next, following an example from `dDocent`, we look for individuals with lots of missing data and exclude from the vcf file.

```{bash, eval = FALSE}
vcftools --vcf ./5.Stacks_ref2/filtered.hwe.recode.vcf --missing-indv
mawk '$5 > 0.9' out.imiss | cut -f1 > lowDP.indv
vcftools --vcf ./05.Stacks/filtered.hwe.maf5.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out ./05.Stacks/filtered.final.maf5
```

We now generated the final vcf file, with 91 individuals and 25,751 high quality SNPs.


#### Convert the vcf file to phylip 

Here we are converting the final vcf file to phylip format to be analysed with [RAxML](https://cme.h-its.org/exelixis/web/software/raxml/) on the [CIPRES](https://www.phylo.org/) server. For the format conversion we use the `vcf2phylip.py` script (Ortiz, 2019), found [here](https://github.com/edgardomortiz/vcf2phylip).

```{bash, eval = FALSE}
cd ./Desktop/biogeography/06.Phylogenetics
python vcf2phylip.py --input filtered.final.maf5.recode.vcf 
```


#### Admxiture analysis

Here we are converting the final vcf file to [plink](zzz.bwh.harvard.edu/plink/) *bed* format to be used in [Admixture](http://software.genetics.ucla.edu/admixture/).

```{bash, eval = FALSE}
plink --vcf ./05.Stacks/filtered.final.maf5.recode.vcf --double-id --allow-extra-chr --make-bed --out ./07.Population_genetics/admixture/filtered.final

plink --bfile ./07.Population_genetics/admixture/filtered.final --double-id --allow-extra-chr --recode12 --tab --out ./07.Population_genetics/admixture/filtered.final
```

Now we can run the **admixture** analysis. First, write a loop script to test different values of *K*. You can use any text editor. The script looks like this:

```{bash, eval = FALSE}
#!/bin/bash

for K in {2..11}
do
admixture --cv=20 $@ $K | tee log${K}.out;
mv *.P ./results;
mv *.Q ./results;
mv *.out ./results;
done

```

Now run the analysis.

```{bash, eval = FALSE}
cd ./07.Population_genetics/admixture
sh ./run_admixture_loop.sh filtered.final.ped
grep -h CV ./results/log*.out
```


#### DAPC analysis in adegenet

First, we need to convert the final vcf file into plink 012 format.

```{bash, eval = FALSE}
plink --vcf ./05.Stacks/filtered.final.maf5.recode.vcf --make-bed --out ./07.Population_genetics/DAPC/filtered.maf5 --allow-extra-chr 

plink --bfile ./07.Population_genetics/DAPC/iltered.maf5 --recode --tab --out ./07.Population_genetics/DAPC/filtered.maf5 --allow-extra-chr 

plink --file ./07.Population_genetics/DAPC/filtered.maf5 --recodeA --out ./07.Population_genetics/DAPC/filtered.maf5 --allow-extra-chr 

plink --file ./07.Population_genetics/DAPC/filtered.maf5 --recode12 --out ./07.Population_genetics/DAPC/filtered.maf5.12 --double-id --allow-extra-chr
```

Now we can run the [DAPC](http://adegenet.r-forge.r-project.org/files/tutorial-dapc.pdf) analysis in the R package adegenet.

```{r, eval = FALSE}
setwd("~/Desktop/biogeography/07.Population_genetics/DAPC/")
library(adegenet)
genlight1 <- read.PLINK("filtered.maf5.raw", map.file="filtered.maf5.map")

groups <- find.clusters(genlight1, max.n.clust=11, n.pca = 90,
                        choose.n.clust = TRUE, criterion = "min")  # find most likely number of clusters

xval1 <- xvalDapc(tab(genlight1, NA.method="mean"), groups$grp, n.pca.max = 90,
                  result = "groupMean", center = TRUE, scale = FALSE, parallel = "multicore",
                  n.pca = NULL, n.rep = 100, xval.plot = TRUE)  # crossalidation to decide how many pcs to retain

dapc1 <- dapc(genlight1, pop = groups$grp, n.pca=10, n.da = 7)  # run dapc

# plot the results
posterior1 <- data.frame(dapc1$posterior)
colnames(posterior1) <- c("alp","lte","lom","haw","nor","bwa","bal")
cols <- c("alp"="#874000","lte"="gold1","lom"="#2372CD","haw"="#DC8C91","nor"="#b08ea2","bwa"="#e3655b","bal"="#6b9080")

barplot(t(posterior1), col = cols, space = 0,
        xlab="Lake", ylab="Ancestry", border=NA,cex.names = 0.000001)
# the colours were then adjusted in inkscape manually!
```
